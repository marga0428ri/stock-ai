import pandas as pd
import yfinance as yf
from datetime import datetime
from sklearn.ensemble import RandomForestClassifier
import feedparser
from textblob import TextBlob
import numpy as np
import time

# --- ğŸ¯ ç›£è¦–å¯¾è±¡ã¨ã€Œ3ã¤ã®è¦–ç‚¹ã€ ---
# æƒ…å ±åé›†ã‚’å€å¢—ã•ã›ã‚‹ãŸã‚ã€å„éŠ˜æŸ„ã«è¤‡æ•°ã®æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’è¨­å®š
STOCKS = [
    # ğŸ‡ºğŸ‡¸ ç±³å›½æ ª
    {
        "ticker": "NVDA", "name": "NVIDIA", "currency": "$",
        "queries": ["NVIDIA stock news", "NVIDIA earnings analysis", "AI chip market demand"]
    },
    {
        "ticker": "AAPL", "name": "Apple", "currency": "$",
        "queries": ["Apple stock news", "iPhone sales report", "tech sector trends"]
    },
    {
        "ticker": "MSFT", "name": "Microsoft", "currency": "$",
        "queries": ["Microsoft stock news", "Azure cloud growth", "software industry news"]
    },
    {
        "ticker": "TSLA", "name": "Tesla", "currency": "$",
        "queries": ["Tesla stock news", "EV market outlook", "Elon Musk news"]
    },
    {
        "ticker": "AMZN", "name": "Amazon", "currency": "$",
        "queries": ["Amazon stock news", "AWS revenue", "e-commerce trends"]
    },
    
    # ğŸ‡¯ğŸ‡µ æ—¥æœ¬æ ª
    {
        "ticker": "7203.T", "name": "Toyota", "currency": "Â¥",
        "queries": ["Toyota Motor stock", "Toyota financial results", "auto industry Japan"]
    },
    {
        "ticker": "6758.T", "name": "Sony Group", "currency": "Â¥",
        "queries": ["Sony Group stock", "PlayStation sales", "image sensor market"]
    },
    {
        "ticker": "7974.T", "name": "Nintendo", "currency": "Â¥",
        "queries": ["Nintendo stock", "Switch console sales", "video game market"]
    },
    {
        "ticker": "8035.T", "name": "Tokyo Electron", "currency": "Â¥",
        "queries": ["Tokyo Electron stock", "semiconductor equipment market", "chip industry news"]
    },
    {
        "ticker": "9983.T", "name": "Fast Retailing", "currency": "Â¥",
        "queries": ["Fast Retailing stock", "Uniqlo sales", "retail apparel trends"]
    }
]

# --- 1. Deep News Analysis (æƒ…å ±åé›†ã®å€å¢—) ---
KEYWORDS_WEIGHT = {
    "record": 2.0, "surge": 1.5, "jump": 1.5, "beat": 1.5, "approval": 2.0,
    "buyback": 1.2, "dividend": 1.2, "acquisition": 1.5, "partnership": 1.2,
    "plunge": -1.5, "miss": -1.5, "drop": -1.2, "fail": -1.5, "lawsuit": -2.0,
    "scandal": -2.5, "cut": -1.2, "downgrade": -1.5, "inflation": -1.0
}

def analyze_deep_news(queries):
    """
    è¤‡æ•°ã®ã‚¯ã‚¨ãƒªã‚’ä½¿ã£ã¦ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’æ·±æ˜ã‚Šã—ã€
    ç·åˆçš„ãªã€Œã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆã‚¹ã‚³ã‚¢ (-1.0 ~ 1.0)ã€ã‚’ç®—å‡ºã™ã‚‹
    """
    total_score = 0
    article_count = 0
    seen_titles = set() # é‡è¤‡è¨˜äº‹ã‚’æ’é™¤

    for query in queries:
        safe_query = query.replace(" ", "+")
        rss_url = f"https://news.google.com/rss/search?q={safe_query}+when:1d&hl=en-US&gl=US&ceid=US:en"
        
        try:
            feed = feedparser.parse(rss_url)
            # å„ã‚¯ã‚¨ãƒªã‹ã‚‰ä¸Šä½5ä»¶ã‚’å–å¾—ï¼ˆåˆè¨ˆæœ€å¤§15ä»¶ï¼‰
            for entry in feed.entries[:5]:
                title = entry.title
                if title in seen_titles: continue
                seen_titles.add(title)

                # A. æ„Ÿæƒ…åˆ†æ
                blob = TextBlob(title)
                polarity = blob.sentiment.polarity
                
                # B. ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰é‡ã¿ä»˜ã‘
                weight = 1.0
                title_lower = title.lower()
                for word, w_val in KEYWORDS_WEIGHT.items():
                    if word in title_lower:
                        weight = w_val # å¼·ã„è¨€è‘‰ãŒã‚ã‚Œã°é‡ã¿ã‚’ä¸Šæ›¸ã
                        break # æœ€ã‚‚å¼·ã„è¨€è‘‰ã‚’å„ªå…ˆ
                
                # é‡ã¿ä»˜ãã‚¹ã‚³ã‚¢ã‚’åŠ ç®—
                total_score += polarity * abs(weight) * (1 if weight > 0 else -1)
                article_count += 1
                
        except Exception:
            continue
            
    if article_count == 0: return 0.0, 0
    
    # å¹³å‡ã‚¹ã‚³ã‚¢ã‚’ç®—å‡º (-1.0 ã€œ 1.0 ã«æ­£è¦åŒ–)
    avg_score = total_score / article_count
    # å°‘ã—å€¤ã‚’å¼·èª¿ã™ã‚‹ï¼ˆãƒ‹ãƒ¥ãƒ¼ã‚¹ã®å½±éŸ¿ã‚’åæ˜ ã—ã‚„ã™ãã™ã‚‹ãŸã‚ï¼‰
    final_sentiment = max(-1.0, min(1.0, avg_score * 1.5))
    
    return final_sentiment, article_count

# --- 2. éå»ãƒ‡ãƒ¼ã‚¿ã¨ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã®å–å¾— ---
def get_market_data(ticker):
    try:
        # éå»1å¹´åˆ†ã®ãƒ‡ãƒ¼ã‚¿
        df = yf.download(ticker, period="1y", progress=False)
        if isinstance(df.columns, pd.MultiIndex):
            df.columns = df.columns.get_level_values(0)
        return df
    except: return pd.DataFrame()

# --- 3. åˆ©ç›Šäºˆæƒ³ãƒ­ã‚¸ãƒƒã‚¯ (Expected Return Calculation) ---
def calculate_expected_profit(df, sentiment_score):
    """
    ã€ã“ã“ãŒæ ¸å¿ƒã€‘
    ãã®æ ªãŒæŒã¤ã€Œå¤‰å‹•ã‚¨ãƒãƒ«ã‚®ãƒ¼(Volatility)ã€ã«ã€Œãƒ‹ãƒ¥ãƒ¼ã‚¹ã®å‹¢ã„ã€ã‚’æ›ã‘åˆã‚ã›ã€
    æ˜æ—¥ã®å…·ä½“çš„ãªäºˆæƒ³åˆ©ç›Š(%)ã‚’è¨ˆç®—ã™ã‚‹ã€‚
    """
    # 1. ãã®æ ªã®ã€Œ1æ—¥ã®å¹³å‡å¤‰å‹•å¹…ã€ã‚’è¨ˆç®—ï¼ˆãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼‰
    # æœ€è¿‘ã®å‹•ãã‚’é‡è¦–ã™ã‚‹ãŸã‚ã€ç›´è¿‘20æ—¥ã®æ¨™æº–åå·®ã‚’ä½¿ã†
    daily_volatility = df["Close"].pct_change().rolling(20).std().iloc[-1]
    
    # ãƒ‡ãƒ¼ã‚¿ãŒå–ã‚Œãªã„å ´åˆã®å®‰å…¨ç­–
    if np.isnan(daily_volatility): daily_volatility = 0.015 # 1.5%ã¨ä»®å®š

    # 2. ãƒ™ãƒ¼ã‚¹ã®ãƒˆãƒ¬ãƒ³ãƒ‰ï¼ˆæœ€è¿‘ä¸ŠãŒã£ã¦ã‚‹ã‹ä¸‹ãŒã£ã¦ã‚‹ã‹ï¼‰
    # 5æ—¥ç§»å‹•å¹³å‡ã¨20æ—¥ç§»å‹•å¹³å‡ã®ä¹–é›¢ç‡
    sma5 = df["Close"].rolling(5).mean().iloc[-1]
    sma20 = df["Close"].rolling(20).mean().iloc[-1]
    trend_strength = (sma5 - sma20) / sma20
    
    # 3. äºˆæƒ³å¤‰å‹•ç‡ã®è¨ˆç®—å¼
    # äºˆæƒ³% = (ãƒˆãƒ¬ãƒ³ãƒ‰ç”±æ¥ã®å¤‰å‹•) + (ãƒ‹ãƒ¥ãƒ¼ã‚¹ç”±æ¥ã®è¡æ’ƒ)
    # ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒãªã„(0)ãªã‚‰ã€ãƒˆãƒ¬ãƒ³ãƒ‰ã«å¾“ã†ã€‚ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒå¼·ã‘ã‚Œã°ã€ãã‚Œã‚’å¤§ããåæ˜ ã€‚
    
    # ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®å½±éŸ¿åŠ›ã‚’ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã®ä½•å€ã«ã™ã‚‹ã‹ï¼ˆæ„Ÿå¿œåº¦ä¿‚æ•°ï¼‰
    impact_factor = 2.0 
    
    expected_change_pct = (trend_strength * 0.3) + (sentiment_score * daily_volatility * impact_factor)
    
    # ç¾å®Ÿçš„ãªç¯„å›²ã«åã‚ã‚‹ï¼ˆ1æ—¥ã§Â±15%ä»¥ä¸Šå‹•ãäºˆæƒ³ã¯ç•°å¸¸å€¤ã¨ã—ã¦ã‚«ãƒƒãƒˆï¼‰
    expected_change_pct = max(-0.15, min(0.15, expected_change_pct))
    
    return expected_change_pct * 100 # %è¡¨è¨˜ã«ã™ã‚‹

# --- 4. ç·åˆåˆ†æå®Ÿè¡Œ ---
def analyze_stock(stock_info):
    ticker = stock_info["ticker"]
    
    # A. ãƒ‡ãƒ¼ã‚¿ã‚’ã˜ã£ãã‚Šå–å¾—
    df = get_market_data(ticker)
    if df.empty or len(df) < 20: return None
    
    # B. ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’æ·±ãèª­ã‚€ï¼ˆ3å€ã®æƒ…å ±é‡ï¼‰
    sentiment, art_count = analyze_deep_news(stock_info["queries"])
    
    # C. åˆ©ç›Šäºˆæƒ³ã‚’è¨ˆç®—
    exp_profit = calculate_expected_profit(df, sentiment)
    
    # D. ã‚¢ã‚¯ã‚·ãƒ§ãƒ³åˆ¤å®š
    # äºˆæƒ³åˆ©ç›ŠãŒãƒ—ãƒ©ã‚¹ãªã‚‰BUYã€ãƒã‚¤ãƒŠã‚¹ãªã‚‰SELLã€å¾®å°ãªã‚‰WAIT
    action = "WAIT âšª"
    if exp_profit > 1.0: action = "BUY ğŸ”µ" # 1%ä»¥ä¸Šã®åˆ©ç›ŠãŒè¦‹è¾¼ã‚ã‚‹ãªã‚‰GO
    if exp_profit > 3.0: action = "STRONG BUY ğŸš€" # 3%ä»¥ä¸Šãªã‚‰æ¿€ç†±
    if exp_profit < -1.0: action = "SELL ğŸ”´"
    if exp_profit < -3.0: action = "STRONG SELL âš¡"
    
    return {
        "name": stock_info["name"],
        "price": df["Close"].iloc[-1],
        "currency": stock_info["currency"],
        "action": action,
        "exp_profit": exp_profit, # äºˆæƒ³åˆ©ç›Š (%)
        "sentiment": sentiment,
        "articles": art_count,
        "volatility": df["Close"].pct_change().rolling(20).std().iloc[-1] * 100
    }

# --- 5. ãƒ¬ãƒãƒ¼ãƒˆä½œæˆï¼ˆäºˆæƒ³åˆ©ç›Šæ¬„ã‚’è¿½åŠ ï¼‰ ---
def update_readme(results_us, results_jp):
    now = datetime.now().strftime("%Y-%m-%d %H:%M (UTC)")
    
    # äºˆæƒ³åˆ©ç›ŠãŒé«˜ã„é †ã«ä¸¦ã¹æ›¿ãˆï¼ˆä¸€ç•ªå„²ã‹ã‚Šãã†ãªæ ªã‚’ä¸Šã«ï¼‰
    results_us.sort(key=lambda x: x["exp_profit"], reverse=True)
    results_jp.sort(key=lambda x: x["exp_profit"], reverse=True)
    
    def make_table(results):
        rows = ""
        for r in results:
            # åˆ©ç›Šäºˆæƒ³ã®è¡¨ç¤ºè‰²ã¥ã‘
            prof_str = f"{r['exp_profit']:+.2f}%"
            if r['exp_profit'] > 0: prof_str = f"**{prof_str}** ğŸ“ˆ"
            elif r['exp_profit'] < 0: prof_str = f"{prof_str} ğŸ“‰"
            
            # ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆã‚¢ã‚¤ã‚³ãƒ³
            sent_icon = "âšª"
            if r['sentiment'] > 0.3: sent_icon = "â˜€ï¸"
            if r['sentiment'] < -0.3: sent_icon = "â˜ï¸"
            
            rows += f"| {r['action']} | {r['name']} | {r['currency']}{r['price']:,.0f} | {prof_str} | {sent_icon} ({r['articles']} news) |\n"
        return rows

    content = f"""# ğŸ”­ Deep Impact Stock Forecast
    
## ğŸ“Š Project Goal
To calculate the **Exact Expected Profit (%)** for tomorrow by analyzing:
1.  **Multi-Angle News:** Analyzing company, financial, and sector news.
2.  **Volatility Energy:** Calculating how much the stock *can* move.

* **Updates:** 3 times daily (Every 8 hours).
* **Focus:** Quality of Information > Frequency of Updates.

---

## ğŸ‡ºğŸ‡¸ US Stocks: Expected Profit
| Action | Stock | Price | **Exp. Profit (Target)** | News Power |
| :--- | :--- | :--- | :--- | :--- |
{make_table(results_us)}

## ğŸ‡¯ğŸ‡µ Japan Stocks: Expected Profit
| Action | Stock | Price | **Exp. Profit (Target)** | News Power |
| :--- | :--- | :--- | :--- | :--- |
{make_table(results_jp)}

### ğŸ’¡ How to read "Exp. Profit"
* **+2.5% ğŸ“ˆ**: AI predicts the price will rise by 2.5% tomorrow based on news impact.
* **-1.2% ğŸ“‰**: Negative news pressure suggests a drop.
* **Logic**: `Volatility` Ã— `News Sentiment Score` = `Expected Move`

---
*Updated: {now}*
"""
    with open("README.md", "w", encoding="utf-8") as f:
        f.write(content)

def main():
    # æ—¥æœ¬æ ªã¨ç±³å›½æ ªã‚’åˆ†ã‘ã¦ãƒªã‚¹ãƒˆåŒ–
    stocks_us = [s for s in STOCKS if s['currency'] == "$"]
    stocks_jp = [s for s in STOCKS if s['currency'] == "Â¥"]
    
    print("--- Analyzing US Stocks ---")
    res_us = [r for s in stocks_us if (r := analyze_stock(s))]
    
    print("--- Analyzing Japan Stocks ---")
    res_jp = [r for s in stocks_jp if (r := analyze_stock(s))]
            
    update_readme(res_us, res_jp)
    print("Done!")

if __name__ == "__main__":
    main()

